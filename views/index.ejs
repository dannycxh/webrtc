<html>
<head>
  <meta charset="utf-8">
  <title>Test page for adapter.js</title>
  <script type="text/javascript">
    function trace(arg) {
      var now = (window.performance.now() / 1000).toFixed(3);
      console.log(now + ': ', arg);
    }
  </script>
</head>
<body>
<h1>Test page for adapter.js</h1>
<script src="/js/webrtc-adapter/release/adapter.js"></script>

The browser is: <span id="browser"></span>
<br>
The browser version is: <span id="browserversion"></span>
<script>
  var browser_display = document.getElementById('browser');
  var version_display = document.getElementById('browserversion');
  browser_display.innerHTML = adapter.browserDetails.browser;
  version_display.innerHTML = adapter.browserDetails.version;
</script>



<video id="gum-local" autoplay playsinline></video>

<div id="errorMsg"></div>

<p class="warning"><strong>Warning:</strong> if you're not using headphones, pressing play will cause feedback.</p>

<p>Display the video stream from <code>getUserMedia()</code> in a video element.</p>

<p>The <code>MediaStream</code> object <code>stream</code> passed to the <code>getUserMedia()</code> callback is in global scope, so you can inspect it from the console.</p>

<!--<script src="/javascripts/webrtc_main.js"></script>-->


<!--//done -->
<!--<p>=====================================take a screenshot=================================================================================================================</p>-->
<!--<button>Take snapshot</button>-->
<!--<canvas></canvas>-->
<!--<script type="text/javascript">-->
  <!--var video = document.querySelector('video');-->
  <!--var canvas = window.canvas = document.querySelector('canvas');-->
  <!--canvas.width = 480;-->
  <!--canvas.height = 360;-->

  <!--var button = document.querySelector('button');-->
  <!--button.onclick = function() {-->
    <!--canvas.width = video.videoWidth;-->
    <!--canvas.height = video.videoHeight;-->
    <!--canvas.getContext('2d').-->
            <!--drawImage(video, 0, 0, canvas.width, canvas.height);-->
  <!--};-->
<!--</script>-->

<!--//done -->
<!--<p>=====================================video to video=================================================================================================================</p>-->
<!--<video id="leftVideo" controls muted>-->
  <!--&lt;!&ndash; NB CORS: https://bugzilla.mozilla.org/show_bug.cgi?id=1177793 &ndash;&gt;-->
  <!--<source src="/images/chrome.webm" type="video/webm" />-->
  <!--<p>This browser does not support the video element.</p>-->
<!--</video>-->

<!--<video id="rightVideo" autoplay controls></video>-->

<!--<script type="text/javascript">-->

  <!--var leftVideo = document.getElementById('leftVideo');-->
  <!--var rightVideo = document.getElementById('rightVideo');-->

  <!--var stream;-->

  <!--function maybeCreateStream() {-->
    <!--if (stream) {-->
      <!--return;-->
    <!--}-->
    <!--if (leftVideo.captureStream) {-->
      <!--stream = leftVideo.captureStream();-->
      <!--rightVideo.srcObject = stream;-->
      <!--console.log('Captured stream from leftVideo with captureStream',-->
              <!--stream);-->
    <!--} else if (leftVideo.mozCaptureStream) {-->
      <!--stream = leftVideo.mozCaptureStream();-->
      <!--rightVideo.srcObject = stream;-->
      <!--console.log('Captured stream from leftVideo with mozCaptureStream()',-->
              <!--stream);-->
    <!--} else {-->
      <!--console.log('captureStream() not supported');-->
    <!--}-->
  <!--}-->

  <!--// Video tag capture must be set up after video tracks are loaded.-->
  <!--leftVideo.oncanplay = maybeCreateStream;-->
  <!--if (leftVideo.readyState >= 3) {  // HAVE_FUTURE_DATA-->
    <!--// Video is already ready to play, call maybeCreateStream in case oncanplay-->
    <!--// fired before we registered the event handler.-->
    <!--maybeCreateStream();-->
  <!--}-->

  <!--leftVideo.play();-->
<!--</script>-->


<!--not yet done-->
<!--<p>=====================================peer to peer=================================================================================================================</p>-->
<!--<video id="localVideo" autoplay muted></video>-->
<!--<video id="remoteVideo" autoplay></video>-->

<!--<div>-->
  <!--<button id="startButton">Start</button>-->
  <!--<button id="callButton">Call</button>-->
  <!--<button id="hangupButton">Hang Up</button>-->
<!--</div>-->
<!--<script type="text/javascript">-->
  <!--var startButton = document.getElementById('startButton');-->
  <!--var callButton = document.getElementById('callButton');-->
  <!--var hangupButton = document.getElementById('hangupButton');-->
  <!--callButton.disabled = true;-->
  <!--hangupButton.disabled = true;-->
  <!--startButton.onclick = start;-->
  <!--callButton.onclick = call;-->
  <!--hangupButton.onclick = hangup;-->

  <!--var startTime;-->
  <!--var localVideo = document.getElementById('localVideo');-->
  <!--var remoteVideo = document.getElementById('remoteVideo');-->

  <!--localVideo.addEventListener('loadedmetadata', function() {-->
    <!--trace('Local video videoWidth: ' + this.videoWidth +-->
            <!--'px,  videoHeight: ' + this.videoHeight + 'px');-->
  <!--});-->

  <!--remoteVideo.addEventListener('loadedmetadata', function() {-->
    <!--trace('Remote video videoWidth: ' + this.videoWidth +-->
            <!--'px,  videoHeight: ' + this.videoHeight + 'px');-->
  <!--});-->

  <!--remoteVideo.onresize = function() {-->
    <!--trace('Remote video size changed to ' +-->
            <!--remoteVideo.videoWidth + 'x' + remoteVideo.videoHeight);-->
    <!--// We'll use the first onsize callback as an indication that video has started-->
    <!--// playing out.-->
    <!--if (startTime) {-->
      <!--var elapsedTime = window.performance.now() - startTime;-->
      <!--trace('Setup time: ' + elapsedTime.toFixed(3) + 'ms');-->
      <!--startTime = null;-->
    <!--}-->
  <!--};-->

  <!--var localStream;-->
  <!--var pc1;-->
  <!--var pc2;-->
  <!--var offerOptions = {-->
    <!--offerToReceiveAudio: 1,-->
    <!--offerToReceiveVideo: 1-->
  <!--};-->

  <!--function getName(pc) {-->
    <!--return (pc === pc1) ? 'pc1' : 'pc2';-->
  <!--}-->

  <!--function getOtherPc(pc) {-->
    <!--return (pc === pc1) ? pc2 : pc1;-->
  <!--}-->

  <!--function gotStream(stream) {-->
    <!--trace('Received local stream');-->
    <!--localVideo.srcObject = stream;-->
    <!--localStream = stream;-->
    <!--callButton.disabled = false;-->
  <!--}-->

  <!--function start() {-->
    <!--trace('Requesting local stream');-->
    <!--startButton.disabled = true;-->
    <!--navigator.mediaDevices.getUserMedia({-->
      <!--audio: true,-->
      <!--video: true-->
    <!--})-->
            <!--.then(gotStream)-->
            <!--.catch(function(e) {-->
              <!--alert('getUserMedia() error: ' + e.name);-->
            <!--});-->
  <!--}-->

  <!--function call() {-->
    <!--callButton.disabled = true;-->
    <!--hangupButton.disabled = false;-->
    <!--trace('Starting call');-->
    <!--startTime = window.performance.now();-->
    <!--var videoTracks = localStream.getVideoTracks();-->
    <!--var audioTracks = localStream.getAudioTracks();-->
    <!--if (videoTracks.length > 0) {-->
      <!--trace('Using video device: ' + videoTracks[0].label);-->
    <!--}-->
    <!--if (audioTracks.length > 0) {-->
      <!--trace('Using audio device: ' + audioTracks[0].label);-->
    <!--}-->
    <!--var servers = null;-->
    <!--pc1 = new RTCPeerConnection(servers);-->
    <!--trace('Created local peer connection object pc1');-->
    <!--pc1.onicecandidate = function(e) {-->
      <!--onIceCandidate(pc1, e);-->
    <!--};-->
    <!--pc2 = new RTCPeerConnection(servers);-->
    <!--trace('Created remote peer connection object pc2');-->
    <!--pc2.onicecandidate = function(e) {-->
      <!--onIceCandidate(pc2, e);-->
    <!--};-->
    <!--pc1.oniceconnectionstatechange = function(e) {-->
      <!--onIceStateChange(pc1, e);-->
    <!--};-->
    <!--pc2.oniceconnectionstatechange = function(e) {-->
      <!--onIceStateChange(pc2, e);-->
    <!--};-->
    <!--pc2.ontrack = gotRemoteStream;-->

    <!--localStream.getTracks().forEach(-->
            <!--function(track) {-->
              <!--pc1.addTrack(-->
                      <!--track,-->
                      <!--localStream-->
              <!--);-->
            <!--}-->
    <!--);-->
    <!--trace('Added local stream to pc1');-->

    <!--trace('pc1 createOffer start');-->
    <!--pc1.createOffer(-->
            <!--offerOptions-->
    <!--).then(-->
            <!--onCreateOfferSuccess,-->
            <!--onCreateSessionDescriptionError-->
    <!--);-->
  <!--}-->

  <!--function onCreateSessionDescriptionError(error) {-->
    <!--trace('Failed to create session description: ' + error.toString());-->
  <!--}-->

  <!--function onCreateOfferSuccess(desc) {-->
    <!--trace('Offer from pc1\n' + desc.sdp);-->
    <!--trace('pc1 setLocalDescription start');-->
    <!--pc1.setLocalDescription(desc).then(-->
            <!--function() {-->
              <!--onSetLocalSuccess(pc1);-->
            <!--},-->
            <!--onSetSessionDescriptionError-->
    <!--);-->
    <!--trace('pc2 setRemoteDescription start');-->
    <!--pc2.setRemoteDescription(desc).then(-->
            <!--function() {-->
              <!--onSetRemoteSuccess(pc2);-->
            <!--},-->
            <!--onSetSessionDescriptionError-->
    <!--);-->
    <!--trace('pc2 createAnswer start');-->
    <!--// Since the 'remote' side has no media stream we need-->
    <!--// to pass in the right constraints in order for it to-->
    <!--// accept the incoming offer of audio and video.-->
    <!--pc2.createAnswer().then(-->
            <!--onCreateAnswerSuccess,-->
            <!--onCreateSessionDescriptionError-->
    <!--);-->
  <!--}-->

  <!--function onSetLocalSuccess(pc) {-->
    <!--trace(getName(pc) + ' setLocalDescription complete');-->
  <!--}-->

  <!--function onSetRemoteSuccess(pc) {-->
    <!--trace(getName(pc) + ' setRemoteDescription complete');-->
  <!--}-->

  <!--function onSetSessionDescriptionError(error) {-->
    <!--trace('Failed to set session description: ' + error.toString());-->
  <!--}-->

  <!--function gotRemoteStream(e) {-->
    <!--if (remoteVideo.srcObject !== e.streams[0]) {-->
      <!--remoteVideo.srcObject = e.streams[0];-->
      <!--trace('pc2 received remote stream');-->
    <!--}-->
  <!--}-->

  <!--function onCreateAnswerSuccess(desc) {-->
    <!--trace('Answer from pc2:\n' + desc.sdp);-->
    <!--trace('pc2 setLocalDescription start');-->
    <!--pc2.setLocalDescription(desc).then(-->
            <!--function() {-->
              <!--onSetLocalSuccess(pc2);-->
            <!--},-->
            <!--onSetSessionDescriptionError-->
    <!--);-->
    <!--trace('pc1 setRemoteDescription start');-->
    <!--pc1.setRemoteDescription(desc).then(-->
            <!--function() {-->
              <!--onSetRemoteSuccess(pc1);-->
            <!--},-->
            <!--onSetSessionDescriptionError-->
    <!--);-->
  <!--}-->

  <!--function onIceCandidate(pc, event) {-->
    <!--getOtherPc(pc).addIceCandidate(event.candidate)-->
            <!--.then(-->
            <!--function() {-->
              <!--onAddIceCandidateSuccess(pc);-->
            <!--},-->
            <!--function(err) {-->
              <!--onAddIceCandidateError(pc, err);-->
            <!--}-->
    <!--);-->
    <!--trace(getName(pc) + ' ICE candidate: \n' + (event.candidate ?-->
                    <!--event.candidate.candidate : '(null)'));-->
  <!--}-->

  <!--function onAddIceCandidateSuccess(pc) {-->
    <!--trace(getName(pc) + ' addIceCandidate success');-->
  <!--}-->

  <!--function onAddIceCandidateError(pc, error) {-->
    <!--trace(getName(pc) + ' failed to add ICE Candidate: ' + error.toString());-->
  <!--}-->

  <!--function onIceStateChange(pc, event) {-->
    <!--if (pc) {-->
      <!--trace(getName(pc) + ' ICE state: ' + pc.iceConnectionState);-->
      <!--console.log('ICE state change event: ', event);-->
    <!--}-->
  <!--}-->

  <!--function hangup() {-->
    <!--trace('Ending call');-->
    <!--pc1.close();-->
    <!--pc2.close();-->
    <!--pc1 = null;-->
    <!--pc2 = null;-->
    <!--hangupButton.disabled = true;-->
    <!--callButton.disabled = false;-->
  <!--}-->
<!--</script>-->


<p>=====================================simple webrtc=================================================================================================================</p>
<script src="https://simplewebrtc.com/latest-v2.js"></script>
<video id="localVideo"></video>
<div id="remoteVideos"></div>
<script type="text/javascript">
  var webrtc = new SimpleWebRTC({
    // the id/element dom element that will hold "our" video
    localVideoEl: 'localVideo',
    // the id/element dom element that will hold remote videos
    remoteVideosEl: 'remoteVideos',
    // immediately ask for camera access
    autoRequestMedia: true

//    string url                        - required url for signaling server. Defaults to signaling server URL which can be used for development. You must use your own signaling server for production.
//    object socketio                   - optional object to be passed as options to the signaling server connection.
//    Connection connection             - optional connection object for signaling. See Connection below. Defaults to a new SocketIoConnection
//     bool debug                       - optional flag to set the instance to debug mode
//    [string|DomElement] localVideoEl  - ID or Element to contain the local video element
//    [string|DomElement] remoteVideosEl- ID or Element to contain the remote video elements
//     bool autoRequestMedia            - optional(=false) option to automatically request user media. Use true to request automatically, or false to request media later with startLocalVideo
//     bool enableDataChannels          - optional(=true) option to enable/disable data channels (used for volume levels or direct messaging)
//     bool autoRemoveVideos            - optional(=true) option to automatically remove video elements when streams are stopped.
//     bool adjustPeerVolume            - optional(=false) option to reduce peer volume when the local participant is speaking
//     number peerVolumeWhenSpeaking    - optional(=.0.25) value used in conjunction with adjustPeerVolume. Uses values between 0 and 1.
//     object media                     - media options to be passed to getUserMedia. Defaults to { video: true, audio: true }. Valid configurations described on MDN with official spec at w3c.
//     object receiveMedia              - optional RTCPeerConnection options. Defaults to { offerToReceiveAudio: 1, offerToReceiveVideo: 1 }.
//     object localVideo                - optional options for attaching the local video stream to the page. Defaults to
  });

  // we have to wait until it's ready
  webrtc.on('readyToCall', function () {
    // you can name it anything
    webrtc.joinRoom('test');
  });
</script>


</body>
</html>